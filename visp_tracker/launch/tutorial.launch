<!-- -*- xml -*-

     This tutorial relies on a recorded video sequence where the
     camera is fixed in front of a cube. The model corresponding to
     this cube is given into the models/laas-box directoy of this
     package.

     See http://www.ros.org/wiki/visp_tracker/Tutorials for more
     information.

  -->
<launch>
  <!-- FIXME: do not use the timestamps from the bag file,
    it makes the tracker hang for some reason. -->
  <param name="use_sim_time" value="false" />

  <!-- Play the video sequence, publish the clock topic to preserve
       the original timestamps. -->
  <node pkg="rosbag" type="play" name="rosbag" args="--clock -l
  $(find visp_tracker)/bag/tutorial-static-box.bag"/>

 <!-- Launch the tracking node -->
  <node pkg="visp_tracker" type="tracker" name="tracker_mbt">
    <param name="camera_prefix" value="/wide_left/camera" />
    <param name="tracker_type" value="mbt+klt" />
  </node>

  <!-- Launch the client (GUI).

       It is mandatory to provide an initial estimation of the object
       position in order to start the tracking. To achieve this, this
       graphical tool can be used. It is not required to call it
       through this launch file, you can also directly call the
       initialization service to provide the initial estimation.

       The model_path variable can either be a standard Unix path or a
       path using the resource_retriever syntax.
       See http://ros.org/wiki/resource_retriever

    -->
  <node pkg="visp_tracker" type="visp_tracker_client" name="tracker_mbt_client">
    <param name="model_path" value="package://visp_tracker/models" />
    <param name="model_name" value="laas-box" />
    <param name="tracker_type" value="mbt+klt" />
    <param name="frame_size" value="0.2" />

    <!-- Load recommended settings for tracking initialization. They
      will be automatically forwarded to the tracking node if the
      initialization succeed. -->
    <rosparam file="$(find visp_tracker)/models/laas-box/tracker.yaml" />
  </node>


  <!-- Launch the viewer (GUI)

       This is totally optional. When the tracker is running on a
       remote computer, it is highly recommended to rely on
       image_transport to stream compressed images. You can use the
       ~image_transport parameter to do so, see the image_transport
       package documentation for more information.
  -->
 <node pkg="visp_tracker" type="visp_tracker_viewer" name="tracker_mbt_viewer">
    <param name="frame_size" value="0.2" />
    <param name="tracker_name" value="tracker_mbt" />
  </node>



  <!--
     Optional: localizing the robot using the tracker.

     This part provides the /map coordinate frame using the tracker.

     The general idea is that the position of a particular object is
     known in the global frame. By comparing the relative position
     between the camera and the oject, the robot position can be
     estimated.
    -->

  <!-- First, provide the transformation from the base_link to the
       camera, static in this example.

       This also converts body frames orientation to camera
       orientation.
       I.e. body frames: x front (toward), y left, z up
            camera frames: z front (toward), x right, y bottom
    -->
  <node pkg="tf" type="static_transform_publisher"
	name="base_link_to_camera" args="0.060 0.072 0.683 -0.542
	0.542 -0.455 0.455 /base_link /camera_wide_left 100" />

  <!-- Second, launch the localization node. Parameters define the
  object position w.r.t. the world frame -->
  <node pkg="visp_tracker" type="tf_localization.py" name="tf_localization">
    <param name="object_translation_x" value="1.8442106300000001" />
    <param name="object_translation_y" value="-0.0083684399999999996" />
    <param name="object_translation_z" value="0.52310595000000004" />

    <param name="object_translation_qx" value="0.04655744" />
    <param name="object_translation_qy" value="-0.12974845" />
    <param name="object_translation_qz" value="-0.45632887" />
    <param name="object_translation_qw" value="0.87906866" />
  </node>
</launch>
